{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Beaver</th>\n",
       "      <th>Duck</th>\n",
       "      <th>Salamander</th>\n",
       "      <th>Walrus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Duck</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Walrus</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Beaver</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Salamander</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Beaver  Duck  Salamander  Walrus\n",
       "Duck             0     1           0       0\n",
       "Walrus           0     0           0       1\n",
       "Beaver           1     0           0       0\n",
       "Salamander       0     0           1       0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = ['Duck', 'Walrus', 'Beaver', 'Salamander']\n",
    "\n",
    "def thing_vector(thing, idx):\n",
    "    return [1 if thing == t else 0 for t in idx]\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    thing : pd.Series(data=thing_vector(thing, idx), index=idx) for thing in idx\n",
    "})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum Likelihood\n",
    "\n",
    "$P(all) = P_1 \\times P_2 \\cdots \\times P_n$\n",
    "\n",
    "We want to maximize this function. The higher the value, the more accurately the model will classify points. However, if we multiply large numbers of sums, the outcome could be drastically modified by just one term. How can we turn products into sums?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\ln b + \\ln b = \\ln ab$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.allclose(np.log(.6) + np.log(.7), np.log(.42))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Entropy\n",
    "\n",
    "Since the result of the natural log of a number less than zero is negative, we can take the negative log of each term to yield a positive number. A good model gives us low cross entropy. We can think of this as the \"error\" of a given point. If the error is low, that means the probability of the point being a correct prediction is high."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error function (binary classification)\n",
    "$$\n",
    "\\displaystyle-\\frac{1}{m}\\sum_{i=1}^m y_i \\ln(\\hat{y}_i) + (1 - y_i)\\ln(1-\\hat{y}_i)\n",
    "$$\n",
    "\n",
    "Error function (multi category)\n",
    "$$\n",
    "\\displaystyle-\\frac{1}{m}\\sum_{i=1}^m \\sum_{i=1}^n y_{ij} \\ln(\\hat{y}_{ij})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that numpy can operate on lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.69314718 -2.30258509 -0.10536052 -2.30258509]\n",
      "[-0.69314718 -0.10536052 -2.30258509 -0.10536052]\n"
     ]
    }
   ],
   "source": [
    "# L cannot have values > 1 since there is no exponent that can make a number negative.\n",
    "L = np.float_([0.5, 0.1, 0.9, 0.1])\n",
    "print(np.log(L))\n",
    "print(np.log(1.0 - L))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function that takes as input two lists Y, P,\n",
    "# and returns the float corresponding to their cross-entropy.\n",
    "\n",
    "# Me üçÑ\n",
    "def cross_entropy(Y, P):\n",
    "    return -1 * sum([yp[0]*np.log(yp[1])+(1-yp[0])*np.log(1-yp[1]) for yp in zip(Y,P)])\n",
    "\n",
    "# Solution\n",
    "def cross_entropy(Y, P):\n",
    "    Y = np.float_(Y)\n",
    "    P = np.float_(P)\n",
    "    return -np.sum(Y * np.log(P) + (1 - Y) * np.log(1 - P))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "Minimizing the error fuction: we minimize through gradient descent.\n",
    "\n",
    "The derivation of logistic regression involves calculating the partial derivative of the error function.\n",
    "\n",
    "The error function is given above. Recall that the sigmoid function $\\sigma$ is defined by:\n",
    "$$\n",
    "\\sigma(x) = \\frac{1}{1+e^{-x}}\n",
    "$$\n",
    "\n",
    "and that $\\hat{y}$ is given by:\n",
    "$$\n",
    "    \\hat{y}_i = \\sigma(W_ix+b)\n",
    "$$\n",
    "We can calculate the gradient:\n",
    "$$\n",
    "    \\nabla E = (\\frac{\\partial}{\\partial w_1}E,\\dots,\\frac{\\partial}{\\partial w_n}E,\\frac{\\partial}{\\partial b}E)\n",
    "$$\n",
    "The sigmoid function has a handy derivative. [A good explanation of derivation of sigmoid function derivative can be found here.](https://beckernick.github.io/sigmoid-derivative-neural-network/)\n",
    "\n",
    "What it is is this: $\\sigma' = \\sigma(x)(1-\\sigma(x))$\n",
    "\n",
    "[TODO: Research derivation]\n",
    "\n",
    "$$\n",
    "    \\nabla E = -(y-\\hat{y})(x_1,\\dots,x_n,1)\n",
    "$$\n",
    "\n",
    "The weights get updated according to the following:\n",
    "$$\n",
    "    w_i' \\longleftarrow w_i + \\alpha(y - \\hat{y})x_i \n",
    "$$\n",
    "and\n",
    "$$\n",
    "    b' \\longleftarrow b + \\alpha(y - \\hat{y})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent Algorithm\n",
    "\n",
    "\n",
    "<ol>\n",
    "    <li>Start with random weights: $ w_1,\\dots,w_n,b $ </li>\n",
    "    <li>For every point: $ x_1,\\dots,x_n $ </li>\n",
    "    <ol>\n",
    "        <li>For $ i = 0 $ to $n$</li>\n",
    "        <ol>\n",
    "            <li>$ w_i' \\longleftarrow w_i + \\alpha(y - \\hat{y})x_i $</li>\n",
    "            <li>$ b' \\longleftarrow b + \\alpha(y - \\hat{y})$ </li>\n",
    "        </ol>\n",
    "    </ol>\n",
    "    <li>Repeat until error is small. </li>\n",
    "</ol>\n",
    "\n",
    "This is very similar to the perceptron algorithm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
